# Journal

A list of readings, quotes, and references to follow up on. This list is in
inverse chronological order with the most recent reads at the top.

## 2015
### July

#### The Science of Managing Data Science

Kate Matsudaira, "The Science of Managing Data Science", Communications of the ACM, vol. 58, no. 6, pp. 44-47.

Quotes:

> - "How are you communicating results? ... We needed more than the measurement of results; we needed success criteria."
> - "When we were creating a model, we would measure the precision and recall of an algorithm and communicate our results that way. However, not all executives speak in those terms. So we started changing the way we talked about experiment results. Instead of putting things in terms of algorithm evaluation metrics (like precision and recall), we started communicating results in terms of the customer experience and business metrics."
> - "Another key when you are doing experiments to improve an algorithm, like tweaking search results, is to show the before and after. What changed with the experiment? Sometimes certain results would be improved, and others would decline, so it was equally important to understand and communicate both sides of the coin. With all the information we could make the best decision about how to proceed."
> - "If you are working in data mining and machine learning research, most of the problems are difficult. The thing is, sometimes the reason why they are hard can be solved in other ways—like better/different data, changing requirements, or adding special cases. So saying a problem would be "really hard" wasn't a good enough reason not to try to solve it; and yet, it was consistently being used as the reason why things were not happening."
> - "The key was learning to communicate why things were difficult."
> - "Adding deadlines to research."
> - "Adding agile demos."

### June

#### A Little Queue Theory

Philip G. Armour, "A Little Queue Theory. When more work means less done.", Communications of the ACM, vol. 58, no. 1, pp. 38-39.

Quotes:

> - "Project Failures are often laid at the door of planning — project failure must be planning failure. This philosophy holds that, if planning is good, more planning is better and more planning will make your project succeed. This might be true for highly deterministic activities, tasks that are predictable and do not vary from their expected course, and tasks that are not subject to volatile internal and external forces. Unfortunately, that does not describe most software projects."
> - "The very high utilization levels to which project managers load their people can only work in fully deterministic systems — systems where the work that needs to be done, when it will be done, by whom, and how long it will take to complete is completely predefined and invariant. This does not describe the business of software at all."
> - "Using two cooperative approaches we should be able to better manage our throughput on projects:"
>   - "Intentionally plan for less than 100% task loading. Effectively managed, the unblocked time a project would allocatie is a workload buffer that can absorb the variation in tasks effort and task priority when unpredicted events occur."
>   - "Measure our work queues; keep track, not only of what is being done, but what is not being done and how long the uncompleted task lists are becoming."

#### The Unreasonable Effectiveness of Data

Alon Halevy, Peter Norvig, Fernando Pereira, "The Unreasonable Effectiveness of Data", IEEE Intelligent Systems, vol. 24, no. 2, pp. 8-12, March/April 2009, doi:10.1109/MIS.2009.36. [[pdf](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35179.pdf)]

References to follow:

 - E. Wigner, "The Unreasonable Effectiveness of Mathematics in the Natural Sciences," Comm. Pure and Applied Mathematics, vol. 13, no. 1, 1960 pp. 1–14.
 - L. Getoor and B. Taskar, Introduction to Statistical Relational Learning, MIT Press, 2007.
 - T. Berners-Lee, J. Hendler, and O. Lassila, "The Semantic Web," Scientific Am., 17 May 2001.

Quotes:

> - "[But] invariably, simple models and a lot of data trump more elaborate models based on less data."
> - "[Similar] observations have been made in every other application of machine learning to Web data: simple *n*-gram models or linear classifiers based on millions of specific features perform better than elaborate models that try to discovery general rules."
> - "For those with experience in small-scale machine learning who are worried about the curse of dimensionality and overfitting of models to data, note that all the experimental evidence from the last decade suggests that throwing away rare events is almost always a bad idea, because much Web data consists of individually rare but collectively frequent events."
> - "Semantic Web versus Semantic Interpretation"
> - "The Semantic Web is a convention for formal representation languages that lets software services interact with each other 'without needing artificial intelligence'."
> - "... use one of several standards for representing dates, prices, and locations."
> - "Semantic interpretation deals with imprecise, ambiguous natural languages, wheras service interoperability deals with making data precise enough that the programs operating on the data will function effectively."
> - "Choose a representation that can use unsupervised learning on unlabeled data, which is so much more plentiful than labeled data. Represent all the data with a nonparametric model rather than trying to summarize it with a parametric model, because with very large data sources, the data holds a lot of detail."
